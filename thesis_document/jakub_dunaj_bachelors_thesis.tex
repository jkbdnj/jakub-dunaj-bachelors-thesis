%%%%%% LaTeX template file for the Bachelor's thesis
%%%%%% Faculty of Civil and Environmental Engineering, TU Wien
%%%%%% The file BachelorBUI.cls must be in the same folder
%%
%% created by Christian Schranz and Sebastian Pech
%% CEE Computer Lab & Digital Building Process
%% date: 2022-10-01
%% tested for pdflatex
%%
\documentclass{BachelorBUI}
%%
%% Packages already loaded in the above document class
%%
%% fontenc[T1], lmodern, microtype, babel[english,ngerman], graphicx,
%% geometry with all margins or areaset (choose what you like)
%% mathtools, amssymb, xfrac, siunitx, booktabs,
%% url, xcolor[table], textcomp, marvosym, pifonts, pdfpages, ragged2e,
%% tabularx, longtable, threeparttable, csquotes, eurosym, enumitem,
%% multirow, setspace, listings, scrlayer-scrpage with header/footline
%% pdfx (including hyperref)
%%
\usepackage[utf8]{inputenc}
\RequirePackage[babel,english=american]{csquotes} %% context sensitive quotations
\raggedbottom
\lstset{
 language={Matlab},
}
\sisetup{output-decimal-marker = {,},
range-phrase = --,
group-separator = {~},
per-mode = symbol,
list-final-separator={ and }}
\graphicspath{{images/}}
\newcommand{\eg}{\mbox{e.\,g.}\xspace}
\newcommand{\Name}[1]{\textsc{#1}}
\newcommand{\vKTxv}{\mathbf{v}_1^T\tilde{\mathbf{K}}_{T},_{\xi}\mathbf{v}_1}
\newcommand{\vKTxxv}{\mathbf{v}_1^T\tilde{\mathbf{K}}_{T},_{\xi\xi}\mathbf{v}_1}
%% biblatex and biber for the bibliography
%% set different citation variants via options:
%% style=numeric-comp ... [1]
%% style=authoryear ... Mang 1998 / use \textcite{} ... Mang (1998)
%%
\usepackage[style=authoryear,backend=biber,maxcitenames=2]{biblatex}
\ExecuteBibliographyOptions{%
 giveninits=true, maxbibnames=99}%
\DefineBibliographyStrings{english}{%
andothers={et\;al\adddot},
urlseen = {Accessed on}
}
\addbibresource{references.bib}
\usepackage{acro}
\acsetup{list/display=used}
\input{acronyms}
% URL hyphenation rules:
\setcounter{biburllcpenalty}{9000}% Lowercase
\setcounter{biburlucpenalty}{9000}% Uppercase
% (see https://texwelt.de/fragen/7008/zeilenumbruche-in-bibliografielinks )
%% Now enter a title
\title{Web-based Application for Plant Disease Classification using Convolutional Neural Networks}
\authorname{Jakub Dunaj} %% Enter your name here
\email{e12121285@student.tuwien.ac.at} %% Enter your email address here
\MatrNr{12121285} %% Enter your student ID number here
\thesislanguage{en-US} %% Language of the thesis (de-AT, de-DE, en-GB, en-US)
\keywords{bachelor thesis\sep template\sep LaTeX}
%% Package pdfx currently incorrectly implemented ... therefore pdfx commented out and hyperref loaded instead
%\usepackage[a-2u,pdf15]{pdfx}
% here the document begins
\begin{document}
\selectlanguage{english}
%% ========== Key Words ==========   
%%
%% Enter some keywords with the \Keywords command and
%% separate them with the \sep command%%
\begin{filecontents}[overwrite]{\jobname.xmpdata}
\makeatletter
\Title{\@title}
\Author{\@authorname}
\Language{\@thesislanguage}
\Keywords{\@keywords}
\Publisher{TU Wien}
\makeatother
\end{filecontents}
%%%%%%%%%
%% Title
%%%%%%%%%
%
\maketitle
% Abstract
\begin{abstract}

Here comes the abstract.

\end{abstract}
% Table of contents
\tableofcontents
\section{Introduction}
\begin{itemize}
    \item different types of plant diseases and their impact on yield loss
\end{itemize}
\section{Literature Review}
To conduct a comprehensive and quality-focused search for scientific literature on the topic of my bachelor's thesis, I utilized two reputable scientific databases: Scopus and IEEE Explore. 
I employed a query-based approach to find the most relevant literature, using the following carefully created search queries: 
\begin{itemize}
    \item \textit{( "crop disease" OR "plant disease" ) AND ( "detection" OR "classification" OR "identification") AND ( "deep learning" )}, 
    \item \textit{( "crop disease" OR "plant disease" ) AND ( "detection" OR "classification" OR "identification") AND ( "deep learning" )  AND ("survey" OR "review")}, 
    \item \textit{( "CNN" ) AND ( "deep learning" ) AND ( "crop disease" OR "plant disease" )},
    \item \textit{( "CNN" ) AND ( "deep learning" ) AND ( "crop disease" OR "plant disease" ) AND ( "review" OR "survey" )},
    \item \textit{( "CNN" ) AND ( "deep learning" ) AND ( "review" OR "survey" )}.
\end{itemize}
% TODO: add citations to the papers (e.g. for the mentioned architectures)
When creating these search queries, I deliberately avoided using too restrictive or too generic keywords or phrases. I have designed the search queries to be specific enough to filter out the irrelevant literature while remaining general enough to keep potentially relevant results. After this initial filtering, I further refined the results based on the publication date and the number of citations. Despite using these methods, many search results failed to meet the criteria for a high quality scientific papers. This became frequently apparent in the faulty usage of English and poor quality of text, pictures, tables, and figures. To overcome this problem, my additional criteria for result selection included the quality of the journal or conference and the reputation of the authors' affiliated institutions. I used this selection process not only for the overall search results returned by the database, but also to a subset of the search results that were filtered by the publication year. My aim was not only to capture the most current knowledge in the researched field, but also to document its successive advances. In addition, I employed the "snowballing" method, using references from already identified papers to discover additional relevant literature. This consistent and rigorous methodology yielded the most relevant, current, and influential papers on crop and plant disease detection using deep learning methods. In summary, my selection process considered not only the citation counts but also the reputations of authors and their affiliated institutions. Consequently, I sometimes selected papers with lower citation counts if they were produced by highly reputable authors or institutions. In the following paragraphs, I will present and review the selected scientific papers to provide a comprehensive and quality-focused overview of the evolution, current advances, and future perspectives in crop and plant disease detection using convolutional neural networks as a deep learning method.

\textcite{Sladojevic:2016} introduced a new approach to detecting plant diseases from leaf images, leveraging the advances in convolutional neural networks and their image classification capabilities. \textcite{Sladojevic:2016} developed a model capable of classifying 13 different plant--disease pairs, one class of healthy leaves and one of leaves without background. The authors created an initial dataset of 13 classes representing different plant-disease combinations by collecting leaf images from the internet. They then added two more classes to the dataset: one containing only images of healthy plant leaves, and another containing images of plant leaves without background. This initial dataset was then preprocessed by cropping the plant leaf images and resizing the images to reduce the training time. This preprocessed dataset was then augmented in order to create large enough dataset. The authors of the paper applied different transformations techniques including affine transformations, perspective transformations, and image rotations. This augmentation phase introduced more variance into the dataset to reduce the overfitting during the training phase. Using the described methods, the authors were able to create a database consisting of 30,880 plant leaf images in the training subset and of 2,589 images in the testing subset. The authors utilized the transfer learning method. To modify the CaffeNet architecture, which was pre-trained on the ImageNet dataset, for the classification of the 15 classes in the created dataset, the authors modified the network's final layer. The trained model achieved the precision between 91\% and 98\% for the different classes. The final overall accuracy was reported to be 96.3\%.

\textcite{Mohanty:2016} utilized the public PlantVillage dataset, initially presented in (\cite{Hughes:2015}), to train two different convolutional neural network architectures, GoogLeNet and AlexNet. The authors trained both architectures under various settings and compared the performances of the trained models based on their ability to detect different plant--disease pairs or healthy leaves. The dataset consisted of 54,306 leaf images of healthy and diseased plants. In total, there were 38 classes created from 14 plants and 26 different diseases in the dataset. The classes corresponded to a plant-disease pair or were dedicated solely to healthy leaves of particular plant species. The healthy or diseased leaf images in the dataset were taken under controlled conditions with neutral background. Across all the experiments the authors conducted, three different versions of the whole dataset were used to train the convolutional neural networks. The authors used the dataset in its original colored version, in its gray-scaled version, and in its segmented version. The segmented version of the original dataset was created by removing all the extra background information in the leaf images that may introduce some bias in the dataset was removed. During the segmentation process the color shift in the leaf images were fixed removing another potential bias in the dataset. Each of these dataset variations was then split into five different dataset configurations used for training and testing of the architectures: 80\% of the dataset used for training and 20\% used for testing, 60\% of the dataset used for training and 40\% used for testing, 50\% of the dataset used for training and 50\% used for testing, 40\% of the dataset used for training and 60\% used for testing, 20\% of the dataset used for training and 80\% used for testing. Furthermore, the authors trained both of the architectures on these datasets from scratch in one case and by adapting these architectures that were already pre-trained on the ImageNet dataset using transfer learning in the other case. In total, these various conditions --- two different CNN architectures, three different versions of the PlantVillage dataset, five different splits of each of these dataset versions into train and test subsets, and two different train approaches --- resulted in 60 different experiments. The hyper-parameter configurations of the training process were kept the same for all of the conducted experiments. The overall accuracy across all of the experiment configurations ranged from 85.53\% to 99.34\%. In the first case of the 85.53\% overall accuracy the AlexNet architecture was trained from scratch on the gray-scale version of the dataset and 80\% of the dataset images were used for training and the remaining 20\% of the dataset were used for the testing of the trained model. In the other case of 99.34\% overall accuracy the GoogLeNet architecture was trained on the original colored version dataset using transfer learning. 80\% of this original dataset were used for training of the model and the remaining 20\% were used for testing. The authors of the paper noticed that with the increase in the train set to test set ration the trained models consistently perform better. The authors also noticed that the models trained on the original colored dataset outperformed the models that were trained using the same configuration but different dataset variation. The exact same behavior was observed by the authors when comparing the models that were trained using the transfer learning to the models trained from scratch. The models trained using transfer learning outperformed those trained from scratch when all other parameters were kept constant. The authors of the paper also identified some limitations to these experiment settings. When the trained models are tested on a datasets of images that are different from those that were used for training, the overall accuracy was reduced to only 31\%. Other limitations of the dataset were also identified. The images were homogeneous, with plant leaves facing upward on a neutral background. Such a dataset does not reproduce real-world conditions and limits the applicability of models trained on it.

\textcite{Ferentinos:2018} trained five different CNN architectures --- AlexNet, AlexNetOWTBn, GoogLeNet, Overfeat, and VGG --- on an extended PlantVillage dataset. This extended dataset consisted of 87,306 leaf images of healthy and diseased plants. The 58 classes comprised in this dataset were as in (\cite{Mohanty:2016}) defined as a plant--disease pair or were dedicated solely to healthy leaves of a specific plant species. More than one third of the images in the dataset were captured under filed conditions. In comparison to the leaf images taken under controlled laboratory conditions, these were more complex in terms of the presence of irrelevant objects, other plant parts, multiple leaves, different background textures, and lighting conditions. The author then divided the initial database into a subset of training images and testing images in a ratio of 80\% to 20\%. The ratio of the images taken in controlled environment and the images taken under real-world conditions was kept the same in both subsets as it was in the original dataset. Another approach to developing the training and testing subsets was the preprocessing of the original dataset by rescaling and cropping the images. The ratio of 80\% to 20\% in terms of training and testing subsets was kept the same. All five architectures were trained using datasets created using both of the approaches. All the five models achieved success rates of over 97\% in both of the experiment settings. The highest success rate of 99.53\% was achieved by the VGG model, and the lowest overall average testing error of 0.0192 was achieved by the AlexNetOWTBn model. Both metrics were achieved on the original dataset. The author then used these two best performing models in another experiment setting to assess the models' ability to generalize between laboratory and field conditions. For this experiment setting, they focused solely on classes that contained images taken under both laboratory conditions and field conditions. From the 58 classes in the original dataset, only 12 contained images of both types. Using these 12 classes, the two models were trained only on the images taken under laboratory conditions and tested on images taken under real-world conditions. Then, the reversed training and testing strategy was applied. The VGG and AlexNetOWTBn models demonstrated varying performance under these experiment setups. When trained on field images and tested on laboratory images, the models achieved success rates of 65.69\% and 62.57\% respectively. When trained on laboratory images and tested on field images, the VGG and AlexNetOWTBn models achieved success rates of 33.27\% and 32.23\% respectively. The study results indicated that the CNN architectures were well suited for the task of classification of plant diseases or the absence thereof from plant leaf images. But as the authors in (\cite{Mohanty:2016}), this study also showed that classifying field images is more challenging than classifying laboratory images. This difficulty arises from increased complexity of field images that have varied backgrounds, inconsistent lightning conditions, and the presence of other for the classification irrelevant objects.

The authors in (\cite{Mohanty:2016}) and (\cite{Ferentinos:2018}) proposed that one of the practical applications of the trained deep learning models could be a mobile application for detecting and diagnosing plant diseases. Such an application would be particularly valuable for farmers in regions lacking the necessary infrastructure for early detection and treatment of plant diseases (\cite{Ferentinos:2018}). This tool could enable the farmers to identify and take appropriate measures at early stages of plant disease development to ensure food safety (\cite{Mohanty:2016}). In both (\cite{Mohanty:2016}) and (\cite{Ferentinos:2018}), the authors concluded that in order to develop and to train accurate plant disease classifiers a large amount of data is required. The results of both scientific papers showed that the data used for training must have grater variety and complexity in terms of background, lighting conditions, geographical locations, and cultivation conditions. \textcite{Ferentinos:2018} concluded the technical feasibility of such an application on modern devices because the classification task requires relatively low computational power.

One of the early approaches to integrate a deep neural network into a mobile application for the detection and classification of plant diseases in environmental conditions was proposed by \cite{Picon:2019}. The work in (\cite{Picon:2019}) is an extension of the previous research done in (\cite{Johannes:2017}). \textcite{Johannes:2017} created a mobile application that used a classical computer vision approach and machine learning techniques to classify early stages of diseases --- septoria, rust, and tan spot --- on wheat leaves. The authors also created a dataset to induce greater variability and complexity in the images, aiming to overcome issues arising from a dataset with low variety and complexity (\cite{Mohanty:2016,Ferentinos:2018}). The images were acquired in Germany and Spain over the course of 3 years staring in 2014. he images were acquired in Germany and Spain over a three-year period, starting in 2014. They were taken in the fields throughout the entire crop season. The identification algorithm pipeline included an image preprocessing stage and a disease identification algorithm based on a primary segmentation module, a Hot-Spot identification module, and a meta-classifier module. The implemented classification algorithm could simultaneously classify these three diseases from a single wheat image. The primary segmentation module used a Naive Bayes classifier to identify potential disease-containing regions and hot spots. The Hot-Spot identification module used two visual descriptors for color and texture information. For every combination of disease and descriptor pair, a Random-forest-based descriptor is trained to assign a feasibility value to the hot spots. The meta-classifier is applied to compute a confidence score for the particular disease by considering different metrics yielded throughout the classification process. The authors used the AuC, the area under a receiver operating characteristic (ROC) curve, metric to evaluate the algorithm's performance. The AuC values range from 0 to 1. When changing the metadata-classifier threshold value starting with 0 all up to 1, each point on the ROC curve is defined by the false positive rate at the x-axis and the true positive rate at the y-axis. The higher the AUC value, the better the underlying algorithm performs in terms of binary classification when compared to AUC values of other methods completing the same task. This means that, on average, the method with a higher AUC value is better at correctly recognizing positive samples while also being better at avoiding falsely identifying negative samples as positive. The study achieved AUC scores above 0.80 for all three diseases in both 10-fold validation and pilot testing deployed in real mobile devices. The accuracy in both testing settings ranged from 73\% to 90\%. When comparing this approach with (\cite{Sladojevic:2016}), (\cite{Mohanty:2016}) or (\cite{Ferentinos:2018}), this classification algorithm performs well under real-world conditions.

\textcite{Picon:2019} developed a mobile application that employed a deep learning approach based on deep residual neural network. The authors of this paper used a deep residual neural network containig 50 layers. Similar to the mobile application described in \textcite{Johannes:2017}, the newly developed application was used to identify early stages of septoria, tan spot, and rust wheat diseases under field conditions. As in (\cite{Johannes:2017}), the classification algorithm was able to simultaneously identify three diseases from a single wheat leaf image. The authors extended the field dataset created in (\cite{Johannes:2017}) by adding over 3,500 new images of the three plant diseases combined into the dataset. In total, the dataset used in this study comprised of 8178 wheat leaf images. To train and validate the proposed classification algorithm, expert technicians labeled the images in the dataset and segmented the disease spots and leaf regions in each image. Furthermore, depending on the development stage of the disease, each diseased leaf was categorized either as early or medium-late. The authors of (\cite{Picon:2019}) outlined one of the main problems related to image classification using CNN architectures. These architectures downscale the input image in order to reduce the number of network parameters and thus reduce the total number of images needed for training. This downscaling process can lead to a significant or even complete loss of information in cases when the disease manifests in small spots on leaves. The authors proposed three methods to modify the image before it is processed by the classification algorithm. In the first method, the image resolution was downscaled to the network input size. The second method involved cropping the original image to extract only the leaf region referred to as the leaf mask. This cropping happened either at the training or the testing stage. The last method involved segmenting the input image into homogenous regions called superpixels. Superpixels not intersecting with the leaf mask were discarded, and the remaining superpixels were resized to the network input size. Each extracted tile was then compared to a corresponding Hot-Spot image representing the actual disease locations on the wheat leaf. To introduce greater variability of the dataset the images were augmented with a random geometric transformation. Each disease class from the dataset was uniformly sampled to ensure equal representation of the diseases in the training dataset. The authors found out that the classification algorithm failed when the disease manifestation closely resembled elements in the image background. To mitigate this problem, a part of the pictures from the training dataset had the background replaced with a random picture. The neural network was modified to extract fine-grained visual features and thus to classify early-stage plant disease manifestations. The last layer of the architecture was replaced by a dense layer with an output size equaling the number of disease classes. This layer was then followed by a sigmoid activation function, replacing the original softmax. This modification allowed classification of multiple diseases in one leaf by assigning the probability to each output independently. The training was conducted for each of the three proposed input methods --- full-size images, leaf mask, and superpixel extraction --- both with and without artificial background augmentation. Images preprocessed using the leaf mask or superpixel extraction methods resulted in higher AuC values compared to using full-size images. Using images with artificial background in the dataset led to higher AuC values for all the three diseases. All of the training configurations, when validated, yielded AuC values above 0.82. To evaluate performance of the trained models, the authors also used the balanced accuracy (BAC) metric, calculated as the average of sensitivity, true positive rate, and specificity, true negative rate, of the particular model. All training configurations reported BAC of over 0.80. When testing under real-world conditions on leaves affected by rust and septoria, the values of the BAC metric were averaged across trained models for each disease. The average BAC value for rust was 0.96 and for septoria 0.89. Thus, as in (\cite{Johannes:2017}), the deep learning approach proposed by \textcite{Picon:2019} performed well not only in the laboratory settings but also under real-world conditions.

\textcite{Barbedo:2018:1} investigated the impact of the dataset size and the variety of the dataset on the performance of the deep learning techniques and architectures. The author stated that studies like \cite{Mohanty:2016} or \cite{Ferentinos:2018}, although reporting high accuracy on the test dataset, were limited by the dataset itself and thus failed on images taken under real-life conditions. The author outlined the main difficulties in creating a comprehensive dataset, such as the extensive visual manifestation of the diseases in plant leaves, the different manifestations of the diseases throughout the development stages, manifestations of multiple diseases on a single leaf, image background, and lighting conditions. All these factors limited the practical use of models created in (\cite{Mohanty:2016}) or (\cite{Ferentinos:2018}). In (\cite{Picon:2019}), it can be observed that the collection of a comprehensive dataset and the training of a model required an extensive amount of time in collecting and preprocessing, as well as expert knowledge. In order to study the impact of dataset size on development of a deep learning model for plant disease classification, \textcite{Barbedo:2018:1} created a dataset of 1,383 images of 12 plant species and 42 different diseases affecting these plant species.In total, the dataset consisted of 76 classes, each representing a unique plant--disease pair. The dataset included disease manifestations not only on leaves but also on stems, flowers, and fruits. The number of images in each class ranged from 37 to 77. About 85\% af the images were taken under real-world conditions. The rest was taken under controlled conditions. The author utilized transfer learning method to train the GoogLeNet architecture. To evaluate the influence of the image background on the model's performance, the author trained two separate models. The first model was trained on the original dataset, and the second model was trained on a dataset containing images with manually removed background. To further increase the dataset variability, the author used different augmentation techniques. The author used different geometric modifications such as rotation and scaling, and color modifications such as brightness, contrast and sharpness adjustments. The final results were obtained using 10-fold cross-validation. The average accuracy of the model when trained on the original dataset for each plant species ranged from 65\% in wheat and common bean to 100\% in cotton. The model trained on the dataset with images with removed backgrounds reported average accuracies ranging from 50\% in wheat to 100\% in cassava and sugarcane. The author also analyzed the impact of background removal on the model's performance in greater detail. The author observed four different effects of the background removal on the accuracies: no significant impact on the accuracies, substantial accuracy improvement, substantial accuracy decrease, and mixed results. For diseases that had very distinct manifestation, within a specific plant species or generally, the background removal had no significant impact on the model's ability to distinguish the different diseases. Background removal had positive impact in model's ability to distinguish diseases when the background occupied significant portion of the image, was busy and vibrant. This suggests that the model was relying too heavily on background information, rather than solely focusing on the disease symptoms present on the leaves. Negative impact of background removal on accuracies was observed in cases, when the manifestations of different diseases were very similar and the model used the background information to distinguish between the diseases. Mixed results occurred due to the presence of phenomena in the dataset described previously. These mixed results were predominantly observed in classes with a higher number of diseases because of the greater variability in the images. The author concluded that the dataset used in this study, while introducing greater variability compared to  (\cite{Mohanty:2016}) or \cite{Ferentinos:2018}, had too few samples to fully capture the variability of diseases that occur in the real world. The trained models were not suitable for practical use due to this limitation imposed by the dataset. For a CNN to learn the characteristics and features from the training dataset effectively, the dataset must be truly comprehensive. When testing images differ significantly from those in the training set, the trained model often fails to classify them accurately.The author also stated that creating a comprehensive dataset containing a large number of plant species and diseases is impractical due to the extensive effort required to collect and accurately label the images. When creating a dataset for training a model to be used in practice, the author proposed focusing on a smaller set of plant species and diseases while increasing the number of images for each class. 

\textcite{Barbedo:2018:2} analyzed the different factors that influence the performance CNN-based tools for plant disease recognition in real-world conditions. In order to analyze the effectiveness of a trained model in classifying plant diseases, the author utilized the transfer learning of the GoogLeNet architecture and trained four models on different modifications of the same dataset. Author employed a variant of the dataset used in (\cite{Barbedo:2018:1}). For the study dataset, the author selected only plant diseases affecting wheat from the full-size dataset. The first model was trained on the unprocessed images. The second model was trained on images with removed background, and the third model was trained on a dataset containing also images of cropped individual lesions and symptom regions. This cropping of the dataset was done manually. The fourth model was trained on the dataset containing also images of individual lesion and symptom regions, but the size was downsampled to match the size of the original study dataset. In each case and for each class the dataset was divided into a training dataset containing 80\% of the images and into a testing dataset containing 20\% of the images. The images in the training dataset were augmented using different geometrical and color transformations. The author used, as in \cite{Barbedo:2018:1}, rotation, mirroring, addition of Gaussian noise, brightness and contrast adjustments. The final accuracies for each of the trained models were obtained using 10-fold cross-validation. The model trained on the original study dataset achieved an accuracy of 76\%. The model trained on images with the background removed achieved an accuracy of 79\%. When trained on a dataset containing cropped images of individual lesions and symptom regions, the model reported an accuracy of 87\%. Finally, the model trained on a downsampled version of the dataset containing cropped lesion and symptom regions achieved an accuracy of 81\%. The results demonstrated that model accuracy improved when dataset variety was increased by both augmentation techniques and the cropping of individual lesion and symptom regions. The author used these results, the underlying datasets, and previous research in the field to outline multiple factors impacting the performance of CNN models trained for plant disease recognition. The factors negatively impacting the robustness of the model in terms of correct classification were: 

\begin{itemize}
    \item labeled datasets of insufficient size and variety,
    \item datasets inadequately representing the symptom variety of diseases found in practice,
    \item covariate shift occurring when there are differences between the distribution of the training data and the distribution of the data on which the model is used,
    \item image backgrounds containing elements that disturb the learning process,
    \item images not captured under a wide range of conditions, \eg, varying geographical locations or lighting conditions,
    \item images containing many spurious elements,
    \item significant symptom variations and different manifestations of diseases,
    \item plant leaves affected by multiple diseases simultaneously, and
    \item diseases presenting similar symptoms.
\end{itemize}

The paper by \textcite{Barbedo:2019} builds upon author's previous research in (\cite{Barbedo:2018:1}) and (\cite{Barbedo:2018:2}). The author reported in (\cite{Barbedo:2018:2})that the model trained on a dataset containing cropped images of individual lesions and symptom regions achieved the best accuracy out of the four models trained using different dataset modifications. In (\cite{Barbedo:2019}), the author explored this phenomenon further and studied the use of images of individual lesion and symptom regions in the dataset, rather than images of whole leaves. The author used a variation of the dataset used in (\cite{Barbedo:2018:1}) and (\cite{Barbedo:2018:2}). The original dataset included 1,567 images of 57 different diseases affecting 14 plant species. In total, the dataset consisted of 79 classes, each representing a unique plant-disease pair. The author expanded the dataset by segmenting the original images into individual lesion and symptom regions. To guide the segmentation process, the author differentiated different types of symptoms: scattered small symptoms, scattered large symptoms, isolated symptoms, widespread symptoms, and powdery spots.The segmentation was done manually. This process increased the total number of images in the study dataset to 46,409. There were two types of experiments conducted: classification and detection experiments. The classification experiments in contrast to the detections experiments didn't include images of healthy plant leaves. The aim of the classification experiments was to identify which specific disease was present, after the diseased leaf had already been detected. The detection experiments, on the other hand, aimed to observe, how including healthy leaves in the dataset impacts the model's ability to detect and classify diseased leafs. For these experiments, the author utilized the transfer learning method to train multiple GoogLeNet models. The models were trained using three dataset variations: the original dataset, the dateset with images without background, and on the expanded dataset. The segmentation process was done manually and was very time consuming. For each class, the dataset was split with 80\% of images for training and 20\% images for validation. The final accuracies for each of the trained models were obtained using 10-fold cross-validation. In both of the cases, the best accuracies were achieved by the models trained on the extended dataset containing also images of individual lesion and symptom regions. In the classification experiment the model achieved an average accuracy 98\% over all classes. In the detection experiment the model achieved an average detection accuracy of 79\% over all classes. The subsequential average classification accuracy was 78\%. The author concluded that these results achieved by models trained on the extended dataset were achieved due to two main dataset characteristics. The extended dataset contained greater count of images when compered to the original dataset. The additional images in the extended dataset created greater variability and thus the model was able to learn more features. The other characteristic was that because of the segmentation the extended dataset had smaller portion of images with background that could interfere the learning process. The author also highlighted several issues with the extended dataset, particularly the class imbalance. Diseases characterized by numerous small lesions were overrepresented in the dataset compared to other diseases. This imbalance in sample distribution led to misclassifications during the classification experiments. The cropping of the image might also lead to lose of the contextual information.

Transfer learning has been a common approach in the previously reviewed articles applied as a training method to train CNN models for plant disease classification. \textcite{Too:2019} focused on the transfer learning method to train CNN architectures for classifying plant diseases from leaf images. Additionally, the authors also evaluated the performance of multiple CNN architectures trained using transfer learning for plant disease classification. In the context of adapting pre-trained models, typically trained on large, general datasets, and training them on specific datasets, fine-tuning is used to describe this method of transfer learning. The authors trained following architectures: VGG with 16 layers, Inception V4, ResNet with 50, 101 and 152 layers, and DenseNet with 121 layers. The models used in this study had pre-trained weights from training on the ImageNet dataset. To train these CNN architectures, the authors used the colored version of the PlantVillage dataset containing 54,306 images divided into 38 classes. The dataset was not augmented in any way. Before the training and testing process, the dataset images were resized to the input size of the CNN architecture currently being trained. The dataset was divided into a training subset containing 80\% of the images and a testing subset containing 20\% of the images. The top layer of each CNN architecture was replaced by a fully connected layer using a softmax activation function with an output size equal to the number of classes in the dataset. The authors also employed the batch normalization technique in order to minimize the internal covariate shift. To evaluate the performance of each model, the accuracy and categorical cross-entropy loss function were computed. For all models, the training and validation were for all of the models except the VGG16 over 98\%. The VGG16 model reported training accuracy of 84\% and validation accuracy of 82\%. Overall, the DenseNet121 model reported the highest validation accuracy of 99.75\% and also the smallest validation loss. The reported results showed that the models trained using transfer learning methods indeed report hight accuracy in plant disease classification task. Similar conclusions were also drawn by \textcite{Mohanty:2016}. While this research paper provides a valuable overview and insights into the transfer learning of CNN architectures for plant disease classification, its results should be considered within the context established by \cite{Mohanty:2016}, \cite{Barbedo:2018:1}, \cite{Barbedo:2018:2}, and \cite{Barbedo:2019}.  The PlantVillage dataset, used for training and validation of the models, was created under controlled conditions and does not encompass the variability found in the real world. As \textcite{Mohanty:2016} observed, these models would likely struggle to accurately classify images taken under real-world conditions.

\textcite{Chen:2020} also researched the transfer learning method to train CNN architectures for classifying plant diseases from leaf images. For this study, the authors modified the VGG19 architecture to enhance the ability of the neural network to learn small lesion and symptom regions. The last convolutional layer of size 3 $\times$ 3 $\times$ 512 (\cite{Simonyan:2015}) in the VGG19 architecture was replaced by an extended convolutional layer with batch normalization and the Swish activation function instead of the ReLu. The batch normalization is a method introduced by \textcite{Szegedy:2015:2} to reduce internal covariate shift and allow higher learning rates. They define internal covariate shift as a phenomenon describing the change in distribution of each layer's inputs caused by the change of parameters, weights and biases, of the previous layers. The batch normalization fixes the means and variances of layer inputs by normalizing each input tho have the zero mean and unit variance (\cite{Szegedy:2015:2}). Batch normalization is applied after processing each mini-batch, which consists of a specific number of input samples (\cite{Szegedy:2015:2}). Swish activation function, also known as SiLU or sigmoid-weighted linear unit, multiplies its input value by the output of the sigmoid function (\cite{Dubey:2022}). ReLU, the rectified linear unit, is the identity function for positive values and 0 for negative values (\cite{Dubey:2022}). Additionally, the extended convolutional layer was followed by two inception modules. An inception module is a subnetwork of a CNN architecture that performs various pooling and convolutional operations in parallel and concatenates the results of these operations (\cite{Szegedy:2015:1,Gu:2018}). The use of an inception module reduces the number of parameters in the network and reduces the computational complexity (\cite{Szegedy:2015:1,Gu:2018}). The final fully connected layers of the VGG19 architecture were replaced by a global pooling layer. This modification decreased training and testing times and lowered memory requirements by reducing the network's parameters. Finally, a fully connected layer with a softmax activation function was added to the the newly created architecture. This newly crated CNN architecture was named INC-VGGN. \textcite{Chen:2020} trained and validated this architecture on two datasets: on the maize diseases subset of the PlantVillage dataset containing 3,852 images and on a custom dataset of nearly 2,000 maize and rice diseased leaf images collected under field conditions. Both datasets were augmented using geometric transformations. The researchers trained additional CNN architectures --- DenseNet, VGGNet, Inception V3, and ResNet --- on the PlantVillage maize subset. All architectures, including the underlying VGG19 architecture of INC-VGGN, were pre-trained on ImageNet. The INC-VGGN model achieved the best performance on the PlantVillage maize subset with an average validation accuracy of 91.83\%. On the custom dataset, the INC-VGGN model reported an average validation accuracy of 86\%. The results further stated that the transfer learning method is a suitable approach to train convolutional neural networks.



\end{document}